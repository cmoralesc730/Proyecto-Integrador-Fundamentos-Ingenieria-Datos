{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XQUEPmnB3mT"
   },
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Una de las fuentes de información más importante para tener el contexto de lo que ocurre en el día a día son las noticias. Muchas veces, la información disponible en ella es únicamente accesible a través de sus páginas web.\n",
    "\n",
    "En esta actividad, explorarás cómo acceder al nombre de los autores, fecha, títulos y texto de artículos en CNN.\n",
    "\n",
    "1. Accede a la siguiente [página](https://edition.cnn.com/2022/09/19/tech/uber-lapsus-cybersecurity-incident/index.html). Utilizando el inspector de elementos observa las etiquetas empleadas para acceder al título, autor, fecha de publicación y texto del artículo.\n",
    "\n",
    "2. Realiza la petición a `https://edition.cnn.com/2022/09/19/tech/uber-lapsus-cybersecurity-incident/index.html` y emplea la función `BeautifulSoup` para poder obtener el objeto de exploración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VkDwZs2V0DEP"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://edition.cnn.com/2022/09/19/tech/uber-lapsus-cybersecurity-incident/index.html\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omU3EeqwJxi0"
   },
   "source": [
    "3. Accede al título del artículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LYEh4GaS0HxT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Uber says hacker group Lapsus$ behind cybersecurity incident\n"
     ]
    }
   ],
   "source": [
    "titulo_tag = soup.find(\"h1\", class_=\"headline__text inline-placeholder vossi-headline-text\")\n",
    "titulo = titulo_tag.get_text(strip=True) if titulo_tag else None\n",
    "print(\"Título:\", titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK-UExi9G72E"
   },
   "source": [
    "4. Accede a la fecha de actualización de artículo. Este se encuentra en un elemento `<p>` que pertenece a la clase `update-time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z-s14shE0Jji"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha de actualización: Updated\n",
      "          3:11 PM EDT, Mon September 19, 2022\n"
     ]
    }
   ],
   "source": [
    "fecha_tag = soup.find(\"div\", class_=\"timestamp vossi-timestamp\")\n",
    "fecha = fecha_tag.get_text(strip=True) if fecha_tag else None\n",
    "print(\"Fecha de actualización:\", fecha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wo1NXFVHVHh"
   },
   "source": [
    "5. Accede al autor del artículo. Este se encuentra en un elemento `<span>` que pertenece a la clase `metadata__byline__author`. Observa el resultado al emplear `find_all()` para acceder únicamente al nombre del autor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RhABxpSi0LFj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autor: Brian Fung\n"
     ]
    }
   ],
   "source": [
    "autor_tag = soup.find(\"span\", class_=\"byline__name\")\n",
    "autor = autor_tag.get_text(strip=True) if autor_tag else None\n",
    "print(\"Autor:\", autor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado de find_all para autor: [<span class=\"byline__name\">Brian Fung</span>]\n",
      "Nombres de autores extraídos: ['Brian Fung']\n"
     ]
    }
   ],
   "source": [
    "autores = soup.find_all(\"span\", class_=\"byline__name\")\n",
    "print(\"Resultado de find_all para autor:\", autores)\n",
    "print(\"Nombres de autores extraídos:\", [a.get_text(strip=True) for a in autores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyC5X1dzIaiY"
   },
   "source": [
    "6. Accede al texto del artículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j0j0eif10fdw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto del artículo:\n",
      " Uber has linked the cybersecurity incident itdisclosed last weekto hackers affiliated with the Lapsus$ gang, a group accused of numerous high-profile corporate data breaches. The company also said the attackers were able to download or access company Slack messages and invoice-related data from an internal tool.\n",
      "In ablog poston Monday, Uber(UBER)said the attackers first gained access to the company’s systems when they successfully convinced a contractor to grant a multi-factor authentication challenge. The contractor’s network password had likely been obtained separately on a dark web marketplace, Uber(UBER)said.\n",
      "“From there, the attacker accessed several other employee accounts which ultimately gave the attacker elevated permissions to a number of tools, including G-Suite and Slack,” the blog post said. “The attacker then posted a message to a company-wide Slack channel, which many of you saw, and reconfigured Uber’s OpenDNS to display a graphic image to employees on some internal sites.”\n",
      "The attacker did not access user-facing systems, user accounts, databases containing personal information or the code that powers Uber’s products, the company said. But it added the investigation is continuing in coordination with law enforcement and multiple cybersecurity firms.\n",
      "The blog post marks the first time Uber has publicly attributed the incident to the Lapsus$ gang, whichtargeted Microsoftearlier this year and is also accused of attacking Nvidia, Okta and other companies.\n",
      "Uber added that in response to the breach, it is strengthening its multifactor authentication policies and has reset employee access to internal tools.\n"
     ]
    }
   ],
   "source": [
    "cuerpo_tag = soup.find(\"div\", class_=\"article__content\")\n",
    "if cuerpo_tag:\n",
    "    parrafos = cuerpo_tag.find_all(\"p\", class_=\"paragraph inline-placeholder vossi-paragraph\")\n",
    "    texto = \"\\n\".join(p.get_text(strip=True) for p in parrafos)\n",
    "else:\n",
    "    texto = None\n",
    "\n",
    "print(\"Texto del artículo:\\n\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i0yj285uqTH"
   },
   "source": [
    "## Ejercicio 2\n",
    "El objetivo de esta ejercicio es poner en práctica lo revisado sobre Web Scrapping con BeautifulSoup, así como el uso de expresiones regulares para procesar la información obtenida.\n",
    "\n",
    "\n",
    "Complete las siguientes instrucciones de esta revisión:\n",
    "\n",
    "1. Descargar, mediante la función get de la biblioteca requests, el contenido del siguiente sitio web:\n",
    "https://archive.org/details/solarsystemcollection?&sort=-week\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onJ8A9Zx0ghx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkUklUxEu9vt"
   },
   "source": [
    "2. Transformar a formato BeautifulSoup para identificar los elementos HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u4sPhAM0hqQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBc1gziJvB_N"
   },
   "source": [
    "\n",
    "3. Acceder a la página web a través de su navegador, seleccionar el nombre de una imagen y entrar en modo inspector para poder ver a qué etiqueta y a qué clase pertenece.\n",
    "\n",
    "4. Encontrar todas las etiquetas \"div\" de la clase \"ttl\" usando la función find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SegpaPtO0xgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eImVh94ZvJjW"
   },
   "source": [
    "5. Mediante un ciclo for que itere sobre dichas etiquetas, extraer únicamente el texto que corresponde al nombre de la imagen, esto con la función .get_text().\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QETDenl00y_C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzo3Ws6lvJbh"
   },
   "source": [
    "6. Ahora obtendremos la cantidad de visualizaciones de cada elemento, para eso, primero hay que encontrar todas las etiquetas \"nobr\" de la clase \"hidden-xs\" usando la función find_all. Notar que esto nos regresa tanto la cantidad de visualizaciones como la fecha de archivo (date archived)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVcjV3HT0-uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldJUcVumvJYn"
   },
   "source": [
    "7. Mediante un ciclo for que itere sobre dichas etiquetas, extraer únicamente el texto que corresponde, en este caso, a la cantidad de visualizaciones y a la fecha de archivo, de nuevo, esto con la función .get_text()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJXIZXeT1Hid"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjwzEnOnvYt5"
   },
   "source": [
    "## Preguntas\n",
    "\n",
    "Después de haber finalizado la ejecución de las instrucciones, contesta lo siguiente:\n",
    "\n",
    "1. ¿Cuál es el tipo de estructura que regresa la función BeautifulSoup()?\n",
    "* BeautifulSoup\n",
    "* bs4.BeautifulSoup\n",
    "* bs4.element.ResultSet\n",
    "\n",
    "\n",
    "2. ¿Cuál es el tipo de estructura que regresa la función .find_all()?\n",
    "* BeautifulSoup\n",
    "* bs4.BeautifulSoup\n",
    "* bs4.element.ResultSet\n",
    "\n",
    "3. ¿Cuántos elementos obtuviste con el primer find_all?\n",
    "* 776\n",
    "* 150\n",
    "* 75\n",
    "\n",
    "\n",
    "4. ¿Cuántos elementos obtuviste con el segundo find_all?\n",
    "* 776\n",
    "* 150\n",
    "* 75\n",
    "\n",
    "\n",
    "5. Respecto a las vistas, ¿cuál es el valor máximo que obtuviste?\n",
    "* 14,924\n",
    "* 107,162\n",
    "* 170,837\n",
    "\n",
    "\n",
    "6. Respecto a las fechas de archivado, ¿cuál es la fecha más reciente que obtuviste?\n",
    "* Sep 17, 2009\n",
    "* Apr 26, 2011\n",
    "* Jan 26, 2012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9g8jN7N1Kfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXHGcdOm1MwB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAA2eVTm1NSI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2rVoyNi1Nnx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fundamentos-ingenieria-datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
